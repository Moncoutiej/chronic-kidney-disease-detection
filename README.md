# Chronic Kidney Disease Detection

In this repository, you can find analysis about the **Chronic Kidney Disease** dataset you can find in [this directory](Chronic_Kidney_Disease/) or directly [here](https://archive.ics.uci.edu/ml/datasets/Chronic_Kidney_Disease) on the [UCI](https://archive.ics.uci.edu/ml/index.php) Website.
This dataset provide 25 feattures which may predict a patient with chronic kidney disease, this work include differents Machine Learning methods comparison to chose the most accurate solution.

> Here the model chosen in the main script is [XGBoost](https://xgboost.readthedocs.io/en/stable/), with a ***macro avg f1 score*** of ~ **98%**

This is the repository architechture :

```txt
.
â”œâ”€â”€ Chronic_Kidney_Disease
â”‚   â”œâ”€â”€ chronic_kidney_disease.arff
â”‚   â”œâ”€â”€ chronic_kidney_disease.info.txt
â”‚   â””â”€â”€ chronic_kidney_disease_full.arff
â”œâ”€â”€ README.md
â”œâ”€â”€ config.json
â”œâ”€â”€ exploration
â”‚   â”œâ”€â”€ CKD_subtypes.ipynb
â”‚   â”œâ”€â”€ EDA.ipynb
â”‚   â””â”€â”€ models.ipynb
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ trainings
    â”œâ”€â”€ XXXXXXXXXXX
    â”‚   â”œâ”€â”€ classification_report.txt
    â”‚   â”œâ”€â”€ confusion_matrix.png
    â”‚   â”œâ”€â”€ infos.json
    â”‚   â””â”€â”€ model_XXXX.pkl

```

- ðŸ“‚ `Chronic_Kidney_Disease` : The dataset used.
- ðŸ“„ `config.json` : The config file where all the differents settings are stored.
- ðŸ“‚ `exploration` : The directory with the differents exploration notebooks :
  - `CKD_subtypes.ipynb` : Notebook to find potential CKD subtypes with clustering method.
  - `EDA.ipynb` : The Exploratory Data Analysis of the dataset this notebook aim to find risk factors for CKD from provided features.
  - `models.ipynb` : The differents models comparisons and feature importance of chosen model.
- ðŸ“„ `main.py` : The main script to launch the Chronic Kidney Disease process. This include data preprocessing, model training and test evaluation.
- ðŸ“„ `requirements.txt` : The python requirement file.
- ðŸ“‚ `trainings` : Folder where the main script is going to create folder and files corresponding to a new training.
In the created folders we can find :
  - ðŸ“„ `classification_report.txt` : Text file with more evaluation informations about the model.
  - ðŸ“„ `model_XXXX.pkl` : File where the model is stored with metric score in the name.
  - ðŸ“„ `infos.json` : Text file with informations about the the model trained (hyperparameters, score, ...).
  - ðŸ“„ `confusion_matrix.png` : Image showing the confusion matrix.

## Instalation

Install [Python 3.9.13](https://www.python.org/downloads/release/python-3913/)

Then to install the differents python packages used in the script and notebooks, you can use [pip](https://pip.pypa.io/en/stable/installation/) :

```shell
cd path/to/repo/directory
pip install -r requirements.txt
```

## Usage

You can read the diferrents notebooks in the [exploration directory](exploration/) to discover the dataset analysis and then launch the main script :

```shell
python3 main.py
```

You can also give a custom config to launch the script :

```shell
python3 main.py --config-path path/to/your/config.json
```
